import pandas as pd
import numpy as np
import time
from merge_files import pipeline_merge
from data_utils import (
    index_map, split_train_val_test,
    check_cold_start, filter_cold_start,
    precision_at_k,recall_at_k
)
from config import TOP_N,ITEM_IDX
import scipy.sparse as sp
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import roc_auc_score

def pivot_table(train_df):
    """
    Creates a user-item interaction matrix (pivot table) from the training DataFrame.

    Parameters
    ----------
    train_df : pandas.DataFrame
        Training dataset containing at least 'user_idx', 'item_idx', and 'is_recommended' columns.

    Returns
    -------
    pandas.DataFrame
        Pivot table where rows represent users, columns represent items,
        and values represent interactions (0/1).

    Raises
    ------
    ValueError
        If the input DataFrame is None or empty.
    """
    if train_df is None or train_df.empty:
        raise ValueError("One or more DataFrames not provided")
    try:
        train_pivot = pd.pivot_table(train_df,index='user_idx',
                                     columns='item_idx',
                                     values='is_recommended',
                                     fill_value=0)

        return train_pivot
    except TabError as e:
        print("ERROR:",e)

def csr_matrix(train_pivot):
    """
    Converts the user-item pivot table into a sparse CSR (Compressed Sparse Row) matrix.

    Parameters
    ----------
    train_pivot : pandas.DataFrame
        Pivot table generated from `pivot_table()`.

    Returns
    -------
    scipy.sparse.csr_matrix
        Sparse user-item matrix representation, optimized for similarity computations.

    Raises
    ------
    ValueError
        If the input pivot table is None or empty.
    """
    if train_pivot is None or train_pivot.empty:
        raise ValueError("One or more DataFrames not provided")
    try:
        matrix = sp.coo_matrix(train_pivot.values).tocsr()
        return matrix
    except IndexError as e:
        print("ERROR:",e)

def calculate_similarity(matrix):
    """
    Computes cosine similarity between users or items.

    Parameters
    ----------
    matrix : scipy.sparse.csr_matrix
        Sparse user-item interaction matrix.

    Returns
    -------
    numpy.ndarray
        Cosine similarity matrix. Shape depends on the axis:
        - User-based: (n_users, n_users)
        - Item-based: (n_items, n_items)

    Raises
    ------
    ValueError
        If the axis parameter is not 'user' or 'item'.
    """
    axis="item"
    if axis not in {"user", "item"}:
        raise ValueError("axis mast to be user or item")
    pivot_matrix = matrix if axis == "user" else matrix.T

    similarity = cosine_similarity(pivot_matrix)

    return similarity

def top_similar_items(similarity, df, item_idx=ITEM_IDX, top_n=TOP_N, verboss=False):
    """
    Retrieves the top-N most similar items for a given item.

    Parameters
    ----------
    similarity : numpy.ndarray
        Item-item similarity matrix generated by `calculate_similarity()`.
    df : pandas.DataFrame
        Original DataFrame containing item information (must include 'item_idx', 'app_id', 'title').
    item_idx : int, optional
        Index of the target item for which recommendations are generated (default=ITEM_IDX).
    top_n : int, optional
        Number of similar items to retrieve (default=TOP_N).
    verboss : bool, optional
        If True, prints the recommended items (default=False).

    Returns
    -------
    numpy.ndarray
        Indices of the top-N similar items.
    """
    sim_scores = similarity[item_idx]         
    similar_items = np.argsort(sim_scores)[::-1][1:top_n+1]  
    recommended_games = df[df['item_idx'].isin(similar_items)][['item_idx','app_id','title']].drop_duplicates()
    if verboss:
        print(recommended_games)
    return similar_items

def evaluate_item_item_cf(train_df, val_df, similarity, k=20):
    """
    Evaluates the Item-Item Collaborative Filtering baseline on a validation set.

    The function computes Precision@K, Recall@K, and AUC by iterating over users
    in the validation set, generating recommendations based on item-item similarity,
    and comparing them to the ground-truth interactions.

    Parameters
    ----------
    train_df : pandas.DataFrame
        Training dataset containing user-item interactions. Must include 'user_idx' and 'item_idx'.
    val_df : pandas.DataFrame
        Validation dataset containing user-item interactions. Must include 'user_idx' and 'item_idx'.
    similarity : numpy.ndarray
        Item-item similarity matrix generated by `calculate_similarity()`.
    k : int, optional
        Cutoff value for Precision@K and Recall@K (default=20).

    Returns
    -------
    dict
        Dictionary containing mean evaluation metrics:
        - 'mean_precision' : float
            Average Precision@K across all users.
        - 'mean_recall' : float
            Average Recall@K across all users.
        - 'mean_auc' : float or None
            Average AUC across all users, or None if AUC could not be computed.
    """

    precision_scores = []
    recall_scores = []
    auc_scores = []

    for user in val_df['user_idx'].unique():
        user_train_items = train_df[train_df['user_idx'] == user]['item_idx'].values
        user_val_items = val_df[val_df['user_idx'] == user]
        if user_val_items.empty:
            continue

        scores = {}
        for item in range(similarity.shape[0]):
            if item in user_train_items:
                continue

            valid_items = [i for i in user_train_items if i < similarity.shape[0]]
            if valid_items:
                scores[item] = similarity[item, valid_items].mean()


        all_items = list(scores.keys())
        y_score = np.array([scores[i] for i in all_items])
        y_true = np.array([1 if i in user_val_items['item_idx'].values else 0 for i in all_items])

        if y_true.sum() > 0:
            prec = precision_at_k(y_true, y_score, k)
            rec = recall_at_k(y_true, y_score, k)
            precision_scores.append(prec)
            recall_scores.append(rec)

            try:
                auc = roc_auc_score(y_true, y_score)
                auc_scores.append(auc)
            except ValueError:
                pass
    
    results = {
    'mean_precision': np.mean(precision_scores),
    'mean_recall': np.mean(recall_scores),
    'mean_auc':np.mean(auc_scores) if auc_scores else None}

    return results

def pipeline_baseline_item_item_cf():
    """
    Runs the full baseline pipeline for Item-Item Collaborative Filtering.

    The pipeline includes:
    1. Data preparation (merge, indexing, train/val/test split).
    2. Cold-start filtering for unseen users/items in validation and test sets.
    3. Pivot table and sparse matrix construction.
    4. Item-item similarity computation (cosine-based).
    5. Evaluation on validation and test sets using Precision@K, Recall@K, and AUC.

    Returns
    -------
    tuple
        results_val : dict
            Dictionary of evaluation metrics on the validation set
            (mean_precision, mean_recall, mean_auc).
        results_test : dict
            Dictionary of evaluation metrics on the test set
            (mean_precision, mean_recall, mean_auc).
        train_time : float
            Runtime in seconds for computing the similarity matrix (fit time).
    """

    df = pipeline_merge()
    df, user2idx, idx2user, item2idx, idx2item = index_map(df)
    train_df, val_df, test_df = split_train_val_test(df)
    train_pivot = pivot_table(train_df)
    cold_start_users_val, cold_start_items_val, cold_start_users_test, cold_start_items_test = check_cold_start(train_df,
                                                                                                    val_df,
                                                                                                    test_df,
                                                                                                    verboss=False)

    val_df, test_df = filter_cold_start(val_df, test_df,
                        cold_start_users_val, cold_start_items_val,
                        cold_start_users_test, cold_start_items_test)

    matrix = csr_matrix(train_pivot)
    start_time = time.time()
    similarity = calculate_similarity(matrix)
    train_time = time.time() - start_time
    similar_items = top_similar_items(similarity,df, item_idx=ITEM_IDX, top_n=TOP_N,verboss=False)
    results_val = evaluate_item_item_cf(train_df, val_df, similarity, k=10)
    results_test = evaluate_item_item_cf(train_df, test_df, similarity, k=10)

    return results_val,results_test,train_time

